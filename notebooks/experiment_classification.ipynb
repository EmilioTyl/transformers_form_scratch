{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment IMDB anlysis with Transformers form scratch\n",
    "Each sample is a sequence of embedded words. Output two positive/negative class\n",
    "Input:\n",
    "* batch of different sample sentences\n",
    "* sample is a sentence of dim t x embedding_size (where t is max sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from _context import src\n",
    "from src.models.model_utils import device_selection\n",
    "#from src.models.predict_model import ClassSequenceTransformer\n",
    "#from src.models import TransformerClassification\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchtext import data, datasets, vocab\n",
    "\n",
    "import numpy as np\n",
    "import random, tqdm, sys, math, gzip\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Params\n",
    "vocab_size = 50000\n",
    "batch_size = 8\n",
    "num_classes = 2\n",
    "embeding_size = 128\n",
    "transformer_heads = 8\n",
    "depth = 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = data.Field(lower=True, include_lengths=True, batch_first=True)\n",
    "label = data.Field(sequential=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = datasets.IMDB.splits(text, label)\n",
    "text.build_vocab(train, max_size=vocab_size - 2)\n",
    "label.build_vocab(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, test_iter = data.BucketIterator.splits((train, test), batch_size=batch_size, device=device_selection())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine maximum sequence\n",
    "max_sequence = max([seq.text[0].size(1) for seq in train_iter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[torchtext.data.batch.Batch of size 8 from IMDB]\n",
       "\t[.text]:('[torch.LongTensor of size 8x633]', '[torch.LongTensor of size 8]')\n",
       "\t[.label]:[torch.LongTensor of size 8]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Explore structure\n",
    "for seq in train_iter:\n",
    "    s = seq\n",
    "    break\n",
    "seq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify Transformer\n",
    "\n",
    "* Seq-to-seq model that does an global average pooling, the resulting vector is projected to a smaller dimension and  at the end and apply a softmax\n",
    "\n",
    "* Positional embeding: each transformer is positional invariant (different order of the inputs produce the same output). Add positional information to the input vectrors by generating positional vectors that are added to the input words. Positional embeding let the model to learn the vector value for position ( does not work well in  sequence lenghts the network has nott seen before). Positional encoding just add a funtion that map position to a vectors, but the network does not learn the mapping, it is an complex hyperparam to fix.\n",
    "\n",
    "<img src=\"images/transformer_model.svg\"  width=\"500\" height=\"600\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.field.Field at 0x152f3b810>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ClassSequenceTransformer(\n",
    "                                    num_classes=num_classes,\n",
    "                                    embeding_size=embeding_size,\n",
    "                                    transformer_heads=transformer_heads,\n",
    "                                    depth=depth,\n",
    "                                    vocab_size=vocab_size,\n",
    "                                    max_sequence=max_sequence,\n",
    "                                    \n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
